{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cse/dual/cs5150278/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/cse/dual/cs5150278/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "/home/cse/dual/cs5150278/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/cse/dual/cs5150278/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/cse/dual/cs5150278/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/cse/dual/cs5150278/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.eager as tfe\n",
    "import pickle\n",
    "tf.logging.set_verbosity(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set PATHs\n",
    "PATH_TO_SENTEVAL = '../'\n",
    "PATH_TO_DATA = './data_evaluation'\n",
    "sys.path.insert(0, PATH_TO_SENTEVAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cse/dual/cs5150278/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# import SentEval\n",
    "import senteval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding(tf.keras.Model):\n",
    "    def __init__(self, V, d):\n",
    "        super(Embedding, self).__init__()\n",
    "        self.W = tfe.Variable(tf.random_uniform(minval=-1.0, maxval=1.0, shape=[V, d]))\n",
    "    \n",
    "    def call(self, word_indexes):\n",
    "        return tf.cast(tf.nn.embedding_lookup(self.W, word_indexes), tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StaticRNN(tf.keras.Model):\n",
    "    def __init__(self, h, cell):\n",
    "        super(StaticRNN, self).__init__()\n",
    "        if cell == 'lstm':\n",
    "            self.cell = tf.nn.rnn_cell.BasicLSTMCell(num_units=h)\n",
    "        elif cell == 'gru':\n",
    "            self.cell = tf.nn.rnn_cell.GRUCell(num_units=h)\n",
    "        else:\n",
    "            self.cell = tf.nn.rnn_cell.BasicRNNCell(num_units=h)\n",
    "        \n",
    "        \n",
    "    def call(self, state, word_vectors, num_words):\n",
    "        word_vectors_time = tf.unstack(word_vectors, axis=1)\n",
    "        outputs, final_state = tf.nn.static_rnn(cell=self.cell, initial_state = state, inputs=word_vectors_time, sequence_length=num_words, dtype=tf.float32)\n",
    "        return outputs, final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, V, d, h, cell):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.word_embedding = Embedding(V, d)\n",
    "        self.rnn = StaticRNN(h, cell)\n",
    "        \n",
    "    def call(self, word_vector, word_length):\n",
    "        word_vectors = self.word_embedding(word_vector)\n",
    "        rnn_outputs_time, final_state = self.rnn(None, word_vectors, word_length)\n",
    "        output = []\n",
    "        for i in range(int(tf.size(word_length))):\n",
    "            output.append(rnn_outputs_time[int(word_length[i]) - 1][i])\n",
    "        t = tf.convert_to_tensor(output, dtype=tf.float32)\n",
    "        return t, final_state, self.word_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(sentences, vocab_table, batch_size):\n",
    "    sentences = tf.convert_to_tensor(sentences)\n",
    "    dataset = tf.data.TextLineDataset.from_tensor_slices(sentences)\n",
    "    dataset = dataset.map(lambda sentence: (\n",
    "        vocab_table.lookup(tf.string_split([(tf.string_split([sentence],',')).values[0]]).values),\n",
    "        tf.size(vocab_table.lookup(tf.string_split([(tf.string_split([sentence],',')).values[0]]).values))\n",
    "                         ))\n",
    "    dataset = dataset.padded_batch(batch_size=batch_size, padded_shapes=([None], []))\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare(params, samples):\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean of the individual word embeddings of each words has been taken\n",
    "import numpy as np\n",
    "def batcher(params, batch):\n",
    "    batch = [sent if sent != [] else ['.'] for sent in batch]\n",
    "    embeddings = []\n",
    "\n",
    "    for sent in batch:\n",
    "        sentvec = []\n",
    "        for word in sent:\n",
    "            if word in params['word2vec']:\n",
    "                sentvec.append(params['word2vec'][word])\n",
    "        if not sentvec:\n",
    "            vec = np.zeros(params['wvec_dim'])\n",
    "            sentvec.append(vec)\n",
    "        sentvec = np.mean(sentvec, 0)\n",
    "        embeddings.append(sentvec)\n",
    "\n",
    "    embeddings = np.vstack(embeddings)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define senteval params\n",
    "params_senteval = {'task_path': PATH_TO_DATA, 'usepytorch': True, 'kfold': 5}\n",
    "params_senteval['classifier'] = {'nhid': 0, 'optim': 'rmsprop', 'batch_size': 128,\n",
    "                                 'tenacity': 3, 'epoch_size': 2}\n",
    "# Set up logger\n",
    "logging.basicConfig(format='%(asctime)s : %(message)s', level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-10-18 02:58:50,411 : ***** Transfer task : MR *****\n",
      "\n",
      "\n",
      "2018-10-18 02:58:50,415 : Generating sentence embeddings\n",
      "2018-10-18 02:58:50,418 : Generated sentence embeddings\n",
      "2018-10-18 02:58:50,422 : Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation\n",
      "2018-10-18 02:58:54,733 : Best param found at split 1: l2reg = 1e-05                 with score 58.67\n",
      "2018-10-18 02:58:55,004 : Best param found at split 2: l2reg = 1e-05                 with score 57.58\n",
      "2018-10-18 02:58:55,275 : Best param found at split 3: l2reg = 1e-05                 with score 57.58\n",
      "2018-10-18 02:58:55,546 : Best param found at split 4: l2reg = 1e-05                 with score 58.33\n",
      "2018-10-18 02:58:55,816 : Best param found at split 5: l2reg = 1e-05                 with score 58.33\n",
      "2018-10-18 02:58:55,832 : Dev acc : 58.1 Test acc : 58.11\n",
      "\n",
      "2018-10-18 02:58:55,835 : ***** Transfer task : CR *****\n",
      "\n",
      "\n",
      "2018-10-18 02:58:55,901 : Generating sentence embeddings\n",
      "2018-10-18 02:58:56,033 : Generated sentence embeddings\n",
      "2018-10-18 02:58:56,037 : Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation\n",
      "2018-10-18 02:58:59,921 : Best param found at split 1: l2reg = 1e-05                 with score 63.76\n",
      "2018-10-18 02:59:03,992 : Best param found at split 2: l2reg = 1e-05                 with score 63.76\n",
      "2018-10-18 02:59:08,066 : Best param found at split 3: l2reg = 1e-05                 with score 63.77\n",
      "2018-10-18 02:59:12,146 : Best param found at split 4: l2reg = 1e-05                 with score 63.75\n",
      "2018-10-18 02:59:16,233 : Best param found at split 5: l2reg = 1e-05                 with score 63.75\n",
      "2018-10-18 02:59:16,465 : Dev acc : 63.76 Test acc : 63.76\n",
      "\n",
      "2018-10-18 02:59:16,469 : ***** Transfer task : SUBJ *****\n",
      "\n",
      "\n",
      "2018-10-18 02:59:16,530 : Generating sentence embeddings\n",
      "2018-10-18 02:59:16,706 : Generated sentence embeddings\n",
      "2018-10-18 02:59:16,709 : Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation\n",
      "2018-10-18 02:59:21,973 : Best param found at split 1: l2reg = 1e-05                 with score 99.6\n",
      "2018-10-18 02:59:27,540 : Best param found at split 2: l2reg = 1e-05                 with score 99.6\n",
      "2018-10-18 02:59:33,113 : Best param found at split 3: l2reg = 1e-05                 with score 99.6\n",
      "2018-10-18 02:59:38,697 : Best param found at split 4: l2reg = 1e-05                 with score 99.6\n",
      "2018-10-18 02:59:44,310 : Best param found at split 5: l2reg = 1e-05                 with score 99.6\n",
      "2018-10-18 02:59:44,611 : Dev acc : 99.6 Test acc : 99.6\n",
      "\n",
      "2018-10-18 02:59:44,614 : ***** Transfer task : MPQA *****\n",
      "\n",
      "\n",
      "2018-10-18 02:59:44,674 : Generating sentence embeddings\n",
      "2018-10-18 02:59:44,947 : Generated sentence embeddings\n",
      "2018-10-18 02:59:44,950 : Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation\n",
      "2018-10-18 02:59:55,783 : Best param found at split 1: l2reg = 1e-05                 with score 68.78\n",
      "2018-10-18 03:00:07,218 : Best param found at split 2: l2reg = 1e-05                 with score 68.78\n",
      "2018-10-18 03:00:18,671 : Best param found at split 3: l2reg = 1e-05                 with score 68.77\n",
      "2018-10-18 03:00:30,133 : Best param found at split 4: l2reg = 1e-05                 with score 68.77\n",
      "2018-10-18 03:00:41,603 : Best param found at split 5: l2reg = 1e-05                 with score 68.77\n",
      "2018-10-18 03:00:42,225 : Dev acc : 68.77 Test acc : 68.77\n",
      "\n",
      "2018-10-18 03:00:42,235 : ***** Transfer task : SST Binary classification *****\n",
      "\n",
      "\n",
      "2018-10-18 03:00:42,658 : Computing embedding for train\n",
      "2018-10-18 03:00:44,897 : Computed train embeddings\n",
      "2018-10-18 03:00:44,900 : Computing embedding for dev\n",
      "2018-10-18 03:00:44,939 : Computed dev embeddings\n",
      "2018-10-18 03:00:44,942 : Computing embedding for test\n",
      "2018-10-18 03:00:45,006 : Computed test embeddings\n",
      "2018-10-18 03:00:45,009 : Training pytorch-MLP-nhid0-rmsprop-bs128 with standard validation..\n",
      "2018-10-18 03:01:05,308 : [('reg:1e-05', 50.92), ('reg:0.0001', 50.92), ('reg:0.001', 50.92), ('reg:0.01', 50.92)]\n",
      "2018-10-18 03:01:05,311 : Validation : best param found is reg = 1e-05 with score             50.92\n",
      "2018-10-18 03:01:05,313 : Evaluating...\n",
      "2018-10-18 03:01:10,384 : \n",
      "Dev acc : 50.92 Test acc : 49.92 for             SST Binary classification\n",
      "\n",
      "2018-10-18 03:01:10,388 : ***** Transfer task : SST Fine-Grained classification *****\n",
      "\n",
      "\n",
      "2018-10-18 03:01:10,563 : Computing embedding for train\n",
      "2018-10-18 03:01:10,855 : Computed train embeddings\n",
      "2018-10-18 03:01:10,858 : Computing embedding for dev\n",
      "2018-10-18 03:01:10,897 : Computed dev embeddings\n",
      "2018-10-18 03:01:10,900 : Computing embedding for test\n",
      "2018-10-18 03:01:10,975 : Computed test embeddings\n",
      "2018-10-18 03:01:10,977 : Training pytorch-MLP-nhid0-rmsprop-bs128 with standard validation..\n",
      "2018-10-18 03:01:13,611 : [('reg:1e-05', 26.25), ('reg:0.0001', 26.25), ('reg:0.001', 26.25), ('reg:0.01', 26.25)]\n",
      "2018-10-18 03:01:13,614 : Validation : best param found is reg = 1e-05 with score             26.25\n",
      "2018-10-18 03:01:13,616 : Evaluating...\n",
      "2018-10-18 03:01:14,278 : \n",
      "Dev acc : 26.25 Test acc : 28.64 for             SST Fine-Grained classification\n",
      "\n",
      "2018-10-18 03:01:14,281 : ***** Transfer task : MRPC *****\n",
      "\n",
      "\n",
      "2018-10-18 03:01:14,413 : Computing embedding for train\n",
      "2018-10-18 03:01:14,693 : Computed train embeddings\n",
      "2018-10-18 03:01:14,696 : Computing embedding for test\n",
      "2018-10-18 03:01:14,814 : Computed test embeddings\n",
      "2018-10-18 03:01:14,835 : Training pytorch-MLP-nhid0-rmsprop-bs128 with 5-fold cross-validation\n",
      "2018-10-18 03:01:20,321 : [('reg:1e-05', 67.54), ('reg:0.0001', 67.54), ('reg:0.001', 67.54), ('reg:0.01', 67.54)]\n",
      "2018-10-18 03:01:20,324 : Cross-validation : best param found is reg = 1e-05             with score 67.54\n",
      "2018-10-18 03:01:20,326 : Evaluating...\n",
      "2018-10-18 03:01:20,660 : Dev acc : 67.54 Test acc 66.49; Test F1 79.87 for MRPC.\n",
      "\n",
      "2018-10-18 03:01:20,665 : ***** Transfer task : SICK-Entailment*****\n",
      "\n",
      "\n",
      "2018-10-18 03:01:20,817 : Computing embedding for train\n",
      "2018-10-18 03:01:21,079 : Computed train embeddings\n",
      "2018-10-18 03:01:21,082 : Computing embedding for dev\n",
      "2018-10-18 03:01:21,113 : Computed dev embeddings\n",
      "2018-10-18 03:01:21,116 : Computing embedding for test\n",
      "2018-10-18 03:01:21,404 : Computed test embeddings\n",
      "2018-10-18 03:01:21,447 : Training pytorch-MLP-nhid0-rmsprop-bs128 with standard validation..\n",
      "2018-10-18 03:01:22,914 : [('reg:1e-05', 56.4), ('reg:0.0001', 56.4), ('reg:0.001', 56.4), ('reg:0.01', 56.4)]\n",
      "2018-10-18 03:01:22,916 : Validation : best param found is reg = 1e-05 with score             56.4\n",
      "2018-10-18 03:01:22,919 : Evaluating...\n",
      "2018-10-18 03:01:23,298 : \n",
      "Dev acc : 56.4 Test acc : 56.69 for                        SICK entailment\n",
      "\n",
      "2018-10-18 03:01:23,305 : ***** Transfer task : SICK-Relatedness*****\n",
      "\n",
      "\n",
      "2018-10-18 03:01:23,357 : Computing embedding for train\n",
      "2018-10-18 03:01:23,756 : Computed train embeddings\n",
      "2018-10-18 03:01:23,759 : Computing embedding for dev\n",
      "2018-10-18 03:01:23,791 : Computed dev embeddings\n",
      "2018-10-18 03:01:23,793 : Computing embedding for test\n",
      "2018-10-18 03:01:24,085 : Computed test embeddings\n",
      "/home/cse/dual/cs5150278/anaconda3/lib/python3.6/site-packages/scipy/stats/stats.py:3003: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  r = r_num / r_den\n",
      "/home/apps/PYTHONPACKAGES/3.6.0/numpy/1.15.0/gnu/lib/python3.6/site-packages/numpy/lib/function_base.py:2400: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/home/apps/PYTHONPACKAGES/3.6.0/numpy/1.15.0/gnu/lib/python3.6/site-packages/numpy/lib/function_base.py:2401: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[None, :]\n",
      "/home/cse/dual/cs5150278/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/home/cse/dual/cs5150278/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/home/cse/dual/cs5150278/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= self.a)\n",
      "2018-10-18 03:01:43,725 : Dev : Pearson 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-10-18 03:01:43,728 : Test : Pearson 0 Spearman 0 MSE 1.0178068645228793                        for SICK Relatedness\n",
      "\n",
      "2018-10-18 03:01:43,734 : \n",
      "\n",
      "***** Transfer task : STSBenchmark*****\n",
      "\n",
      "\n",
      "2018-10-18 03:01:43,880 : Computing embedding for train\n",
      "2018-10-18 03:01:44,237 : Computed train embeddings\n",
      "2018-10-18 03:01:44,240 : Computing embedding for dev\n",
      "2018-10-18 03:01:44,333 : Computed dev embeddings\n",
      "2018-10-18 03:01:44,335 : Computing embedding for test\n",
      "2018-10-18 03:01:44,421 : Computed test embeddings\n",
      "2018-10-18 03:02:09,092 : Dev : Pearson 0\n",
      "2018-10-18 03:02:09,095 : Test : Pearson 0 Spearman 0 MSE 2.4952048630823445                        for SICK Relatedness\n",
      "\n",
      "2018-10-18 03:02:09,101 : ***** Transfer task : STS12 *****\n",
      "\n",
      "\n",
      "/home/cse/dual/cs5150278/ankur-deep-learning/submission/senteval/utils.py:39: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.dot(u, v) / (np.linalg.norm(u) * np.linalg.norm(v))\n",
      "2018-10-18 03:02:09,251 : MSRpar : pearson = nan, spearman = nan\n",
      "2018-10-18 03:02:09,357 : MSRvid : pearson = nan, spearman = nan\n",
      "2018-10-18 03:02:09,424 : SMTeuroparl : pearson = nan, spearman = nan\n",
      "2018-10-18 03:02:09,529 : surprise.OnWN : pearson = nan, spearman = nan\n",
      "2018-10-18 03:02:09,588 : surprise.SMTnews : pearson = nan, spearman = nan\n",
      "2018-10-18 03:02:09,591 : ALL (weighted average) : Pearson = nan,             Spearman = nan\n",
      "2018-10-18 03:02:09,593 : ALL (average) : Pearson = nan,             Spearman = nan\n",
      "\n",
      "2018-10-18 03:02:09,595 : ***** Transfer task : STS13 (-SMT) *****\n",
      "\n",
      "\n",
      "2018-10-18 03:02:09,645 : FNWN : pearson = nan, spearman = nan\n",
      "2018-10-18 03:02:09,750 : headlines : pearson = nan, spearman = nan\n",
      "2018-10-18 03:02:09,832 : OnWN : pearson = nan, spearman = nan\n",
      "2018-10-18 03:02:09,834 : ALL (weighted average) : Pearson = nan,             Spearman = nan\n",
      "2018-10-18 03:02:09,836 : ALL (average) : Pearson = nan,             Spearman = nan\n",
      "\n",
      "2018-10-18 03:02:09,838 : ***** Transfer task : STS14 *****\n",
      "\n",
      "\n",
      "2018-10-18 03:02:09,935 : deft-forum : pearson = nan, spearman = nan\n",
      "2018-10-18 03:02:09,983 : deft-news : pearson = nan, spearman = nan\n",
      "2018-10-18 03:02:10,089 : headlines : pearson = nan, spearman = nan\n",
      "2018-10-18 03:02:10,197 : images : pearson = nan, spearman = nan\n",
      "2018-10-18 03:02:10,304 : OnWN : pearson = nan, spearman = nan\n",
      "2018-10-18 03:02:10,412 : tweet-news : pearson = nan, spearman = nan\n",
      "2018-10-18 03:02:10,415 : ALL (weighted average) : Pearson = nan,             Spearman = nan\n",
      "2018-10-18 03:02:10,417 : ALL (average) : Pearson = nan,             Spearman = nan\n",
      "\n",
      "2018-10-18 03:02:10,419 : ***** Transfer task : STS15 *****\n",
      "\n",
      "\n",
      "2018-10-18 03:02:10,539 : answers-forums : pearson = nan, spearman = nan\n",
      "2018-10-18 03:02:10,646 : answers-students : pearson = nan, spearman = nan\n",
      "2018-10-18 03:02:10,703 : belief : pearson = nan, spearman = nan\n",
      "2018-10-18 03:02:10,809 : headlines : pearson = nan, spearman = nan\n",
      "2018-10-18 03:02:10,915 : images : pearson = nan, spearman = nan\n",
      "2018-10-18 03:02:10,918 : ALL (weighted average) : Pearson = nan,             Spearman = nan\n",
      "2018-10-18 03:02:10,920 : ALL (average) : Pearson = nan,             Spearman = nan\n",
      "\n",
      "2018-10-18 03:02:10,922 : ***** Transfer task : STS16 *****\n",
      "\n",
      "\n",
      "2018-10-18 03:02:11,036 : answer-answer : pearson = nan, spearman = nan\n",
      "2018-10-18 03:02:11,073 : headlines : pearson = nan, spearman = nan\n",
      "2018-10-18 03:02:11,110 : plagiarism : pearson = nan, spearman = nan\n",
      "2018-10-18 03:02:11,151 : postediting : pearson = nan, spearman = nan\n",
      "2018-10-18 03:02:11,183 : question-question : pearson = nan, spearman = nan\n",
      "2018-10-18 03:02:11,186 : ALL (weighted average) : Pearson = nan,             Spearman = nan\n",
      "2018-10-18 03:02:11,188 : ALL (average) : Pearson = nan,             Spearman = nan\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MR': {'devacc': 58.1, 'acc': 58.11, 'ndev': 74, 'ntest': 74}, 'CR': {'devacc': 63.76, 'acc': 63.76, 'ndev': 3775, 'ntest': 3775}, 'SUBJ': {'devacc': 99.6, 'acc': 99.6, 'ndev': 5020, 'ntest': 5020}, 'MPQA': {'devacc': 68.77, 'acc': 68.77, 'ndev': 10606, 'ntest': 10606}, 'SST2': {'devacc': 50.92, 'acc': 49.92, 'ndev': 872, 'ntest': 1821}, 'SST5': {'devacc': 26.25, 'acc': 28.64, 'ndev': 1101, 'ntest': 2210}, 'MRPC': {'devacc': 67.54, 'acc': 66.49, 'f1': 79.87, 'ndev': 4076, 'ntest': 1725}, 'SICKEntailment': {'devacc': 56.4, 'acc': 56.69, 'ndev': 500, 'ntest': 4927}, 'SICKRelatedness': {'devpearson': 0, 'pearson': 0, 'spearman': 0, 'mse': 1.0178068645228793, 'yhat': array([3.51593995, 3.51593995, 3.51593995, ..., 3.51593995, 3.51593995,\n",
      "       3.51593995]), 'ndev': 500, 'ntest': 4927}, 'STSBenchmark': {'devpearson': 0, 'pearson': 0, 'spearman': 0, 'mse': 2.4952048630823445, 'yhat': array([3.01985016, 3.01985016, 3.01985016, ..., 3.01985016, 3.01985016,\n",
      "       3.01985016]), 'ndev': 1500, 'ntest': 1379}, 'STS12': {'MSRpar': {'pearson': (nan, 1.0), 'spearman': SpearmanrResult(correlation=nan, pvalue=nan), 'nsamples': 750}, 'MSRvid': {'pearson': (nan, 1.0), 'spearman': SpearmanrResult(correlation=nan, pvalue=nan), 'nsamples': 750}, 'SMTeuroparl': {'pearson': (nan, 1.0), 'spearman': SpearmanrResult(correlation=nan, pvalue=nan), 'nsamples': 459}, 'surprise.OnWN': {'pearson': (nan, 1.0), 'spearman': SpearmanrResult(correlation=nan, pvalue=nan), 'nsamples': 750}, 'surprise.SMTnews': {'pearson': (nan, 1.0), 'spearman': SpearmanrResult(correlation=nan, pvalue=nan), 'nsamples': 399}, 'all': {'pearson': {'mean': nan, 'wmean': nan}, 'spearman': {'mean': nan, 'wmean': nan}}}, 'STS13': {'FNWN': {'pearson': (nan, 1.0), 'spearman': SpearmanrResult(correlation=nan, pvalue=nan), 'nsamples': 189}, 'headlines': {'pearson': (nan, 1.0), 'spearman': SpearmanrResult(correlation=nan, pvalue=nan), 'nsamples': 750}, 'OnWN': {'pearson': (nan, 1.0), 'spearman': SpearmanrResult(correlation=nan, pvalue=nan), 'nsamples': 561}, 'all': {'pearson': {'mean': nan, 'wmean': nan}, 'spearman': {'mean': nan, 'wmean': nan}}}, 'STS14': {'deft-forum': {'pearson': (nan, 1.0), 'spearman': SpearmanrResult(correlation=nan, pvalue=nan), 'nsamples': 450}, 'deft-news': {'pearson': (nan, 1.0), 'spearman': SpearmanrResult(correlation=nan, pvalue=nan), 'nsamples': 300}, 'headlines': {'pearson': (nan, 1.0), 'spearman': SpearmanrResult(correlation=nan, pvalue=nan), 'nsamples': 750}, 'images': {'pearson': (nan, 1.0), 'spearman': SpearmanrResult(correlation=nan, pvalue=nan), 'nsamples': 750}, 'OnWN': {'pearson': (nan, 1.0), 'spearman': SpearmanrResult(correlation=nan, pvalue=nan), 'nsamples': 750}, 'tweet-news': {'pearson': (nan, 1.0), 'spearman': SpearmanrResult(correlation=nan, pvalue=nan), 'nsamples': 750}, 'all': {'pearson': {'mean': nan, 'wmean': nan}, 'spearman': {'mean': nan, 'wmean': nan}}}, 'STS15': {'answers-forums': {'pearson': (nan, 1.0), 'spearman': SpearmanrResult(correlation=nan, pvalue=nan), 'nsamples': 375}, 'answers-students': {'pearson': (nan, 1.0), 'spearman': SpearmanrResult(correlation=nan, pvalue=nan), 'nsamples': 750}, 'belief': {'pearson': (nan, 1.0), 'spearman': SpearmanrResult(correlation=nan, pvalue=nan), 'nsamples': 375}, 'headlines': {'pearson': (nan, 1.0), 'spearman': SpearmanrResult(correlation=nan, pvalue=nan), 'nsamples': 750}, 'images': {'pearson': (nan, 1.0), 'spearman': SpearmanrResult(correlation=nan, pvalue=nan), 'nsamples': 750}, 'all': {'pearson': {'mean': nan, 'wmean': nan}, 'spearman': {'mean': nan, 'wmean': nan}}}, 'STS16': {'answer-answer': {'pearson': (nan, 1.0), 'spearman': SpearmanrResult(correlation=nan, pvalue=nan), 'nsamples': 254}, 'headlines': {'pearson': (nan, 1.0), 'spearman': SpearmanrResult(correlation=nan, pvalue=nan), 'nsamples': 249}, 'plagiarism': {'pearson': (nan, 1.0), 'spearman': SpearmanrResult(correlation=nan, pvalue=nan), 'nsamples': 230}, 'postediting': {'pearson': (nan, 1.0), 'spearman': SpearmanrResult(correlation=nan, pvalue=nan), 'nsamples': 244}, 'question-question': {'pearson': (nan, 1.0), 'spearman': SpearmanrResult(correlation=nan, pvalue=nan), 'nsamples': 209}, 'all': {'pearson': {'mean': nan, 'wmean': nan}, 'spearman': {'mean': nan, 'wmean': nan}}}}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    #load the english vocab\n",
    "    from tensorflow.python.ops import lookup_ops\n",
    "    english_vocab_file = './data/english_vocab.txt'\n",
    "    english_vocab_table = lookup_ops.index_table_from_file(english_vocab_file, default_value=0)\n",
    "    keys = english_vocab_table.export()[0].numpy()\n",
    "    values = english_vocab_table.export()[1].numpy()\n",
    "    word2index = {k: v for k, v in zip(keys, values)}\n",
    "    params_senteval['word2vec'] = word2index\n",
    "    \n",
    "    #assign dimensions\n",
    "    params_senteval['wvec_dim'] = 256\n",
    "    \n",
    "    #loading the final trained model\n",
    "    opt = tf.train.AdamOptimizer(learning_rate=0.002)\n",
    "    encoder_nmt = Encoder(english_vocab_table.size(), 256, 512, 'gru')\n",
    "    checkpoint_dir = './encoder_nmt'\n",
    "    root = tfe.Checkpoint(optimizer=opt, model=encoder_nmt, optimizer_step=tf.train.get_or_create_global_step())\n",
    "    root.restore(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "    params_senteval['word_embedding'] = encoder_nmt.word_embedding\n",
    "    \n",
    "    \n",
    "    #running the evalutaton tasks\n",
    "    se = senteval.engine.SE(params_senteval, batcher, prepare)\n",
    "    transfer_tasks = ['MR', 'CR', 'SUBJ','MPQA', 'SST2', 'SST5', 'MRPC',\n",
    "                      'SICKEntailment', 'SICKRelatedness', 'STSBenchmark',\n",
    "                     'STS12', 'STS13', 'STS14', 'STS15', 'STS16']\n",
    "    results = se.eval(transfer_tasks)\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
